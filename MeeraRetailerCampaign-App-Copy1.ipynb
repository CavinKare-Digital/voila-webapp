{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Images/meera-logo.png\" width=120 height=120 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Meera Retailer Campaign Diwali 2020</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"Images/8902979023160.jpg\" alt=\"Drawing\" style=\"width: 80px;height: 80px\"/> </td>\n",
    "<td> <img src=\"Images/8902979023177.png\" alt=\"Drawing\" style=\"width: 50px;height: 80px\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "* Choose random retailers satisfying certain criteria providing weights based on the purchasing ability of retailers\n",
    "* Choose the number of random retailers based on the weightage of number of retailers under each AM & retail group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory History_csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = \"History_csv\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1602233271641
    }
   },
   "outputs": [],
   "source": [
    "# Numpy & Pandas for calcs & dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Random pick\n",
    "import random\n",
    "\n",
    "# Azure data & credentials\n",
    "#from ckpackages import azsql\n",
    "\n",
    "# Move files to folder\n",
    "import shutil\n",
    "import os,time\n",
    "import datetime\n",
    "import datetime as dt\n",
    "\n",
    "# Merge csv into one\n",
    "from glob import glob\n",
    "\n",
    "# IPY - VOILA \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import widgets,Button, Output, VBox,interactive,interact,IntProgress\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1602237990497
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# azureml-core of version 1.0.72 or higher is required\r\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\r\n",
    "from azureml.core import Workspace, Dataset\r\n",
    "\r\n",
    "subscription_id = '254dfb48-9c07-4b28-aea1-4a926b010bee'\r\n",
    "resource_group = 'CKDIGITAL'\r\n",
    "workspace_name = 'CKML_Workspace'\r\n",
    "\r\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\r\n",
    "\r\n",
    "dataset = Dataset.get_by_name(workspace, name='v_PC_MeeraRetailerCampaign')\r\n",
    "data = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1602233336547
    }
   },
   "outputs": [],
   "source": [
    "## Move last day results to history\n",
    "path = os.getcwd()\n",
    "\n",
    "now = dt.datetime.now()\n",
    "ago = now-dt.timedelta(hours=24)\n",
    "strftime = \"%H:%M %m/%d/%Y\"\n",
    "created = os.path.join(path + '\\Results_csv')\n",
    "dest = os.path.join(path + '\\History_csv')\n",
    "\n",
    "# Detect files from one folder created or modified in the past 24 hours\n",
    "for root, dirs,files in os.walk(created):  \n",
    "    for fname in files:\n",
    "        path = os.path.join(root, fname)\n",
    "        st = os.stat(path)    \n",
    "        mtime = dt.datetime.fromtimestamp(st.st_mtime)\n",
    "        if mtime > ago:\n",
    "            print(\"True:  \", fname, \" at \", mtime.strftime(\"%H:%M %m/%d/%Y\"))\n",
    "            #shutil.move(path, dest)\n",
    "            # this is actual move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e9861066265c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Convert InvDate to Date format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "## Read & join csv in same folder\n",
    "a = os.getcwd()\n",
    "path = a + '\\\\History_csv'\n",
    "all_files = glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "df_concat = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Convert InvDate to Date format\n",
    "df_concat['InvDate'] = pd.to_datetime(df_concat['InvDate'])\n",
    "\n",
    "## Filter data by instances occuring in last week\n",
    "days=7 #Last 6 days from current date\n",
    "cutoff_date = df_concat['InvDate'].max() - pd.Timedelta(days=days)\n",
    "max_date = df_concat['InvDate'].max()\n",
    "#print(cutoff_date)\n",
    "\n",
    "df1_concat = df_concat[(df_concat['InvDate'] >= cutoff_date)]\n",
    "df1_concat = df_concat[(df_concat['InvDate'] < max_date)]\n",
    "\n",
    "# List of last 6 days unique retailers\n",
    "rtr_last6days = df1_concat[['RtrCode','RtrName']].drop_duplicates()\n",
    "rtrlist_last6days = rtr_last6days['RtrCode'].tolist()\n",
    "rtrnames_last6days = rtr_last6days['RtrName'].tolist()\n",
    "\n",
    "# Filter retailer occuring in last 6 days (to be included below)\n",
    "#data_filtered = data[~data.RtrCode.isin(rtr_last6days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arul murugan store', 'JAIBAIRAVI TRADERS', 'SRI MURUGAN SUPER MARKET', 'AKSHYA TRADERS', 'R.C.TRADERS', 'G.v traders ', 'VANAJA STORES ', 'NEW BALAJI STORE.', 'ANNAMALAI  TRADERS', 'ARUL  MURUGAN   STORE', 'Lakshmi MALLIGAI', 'Bhaju store', 'Mohammed zain', 'National Store', 'SRI KANNA STORE', 'VISVAAM STORE', 'JAYAMURUGAN STORE', 'SARAVANA STORE', 'GREEN BAZAAR ', 'SAIYED ARABHADH ', 'MATHINA STORE', 'SIVA RICE MALLIGAI ', 'Murugan Stores Super Market', 'Stmmaligai', 'Srivigneswarastore', 'Matha store', 'Iruthay meri', 'Welcome stores', 'Anitha stores', 'NEW NELLAI STORR', 'Pasumai supermarket', 'SRI JAYAM MALIGAI STORE', 'BILLAL MALIGAI ', 'SRI KRISHNA SUPER MARKET', 'S.R VETRI STORE', 'APPLE SHOPPING MALL', 'LAKSHMI BANGLES', 'ARUNA AGENCIES', 'm.h yosuf store']\n"
     ]
    }
   ],
   "source": [
    "print('\\nList of retailers selected in last week:')\n",
    "print(rtrnames_last6days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gather": {
     "logged": 1602238120263
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Date:  2020-10-08\n",
      "Unique retailers: 127\n",
      "\n",
      "Choose number of Lots\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7dee068c614c4cac4c9e0a5cfdad0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=55, description='Lots', min=10), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d8f066bd8c48d3a75396fd08e56248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Pick', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Import data\n",
    "Query = 'select * from v_PC_MeeraRetailerCampaign' \n",
    "#data = callstatement(Query)\n",
    "\n",
    "# Add weekday & current weekday\n",
    "data['weekday'] = data['InvDate'].dt.dayofweek\n",
    "currentWeekDay = dt.datetime.now().weekday()\n",
    "\n",
    "# Data only for Latest date\n",
    "# On monday, get Sat & Sun data, for other days, get previous day data\n",
    "if currentWeekDay==0:\n",
    "    cutoff_date = data['InvDate'].max() - pd.Timedelta(days=1)\n",
    "    max_date = data['InvDate'].max()\n",
    "    \n",
    "    data = data[(data['InvDate'] >= cutoff_date)]\n",
    "    data = data[(data['InvDate'] <= max_date)]\n",
    "else:\n",
    "    data = data[data['InvDate'] == data['InvDate'].max()]\n",
    "\n",
    "## Remove null - Retailers without AM\n",
    "# Consider Data with AMName ( remove nulls)\n",
    "data = data[data['AMName'].notnull()]\n",
    "\n",
    "# Categories retail group as Wholesale & Retail\n",
    "data['RtrGroupCde1'] = data['RtrGroupCde'].apply(lambda x: 'PC-WHOLESALE' if x=='PC-WHOLESALE' else 'PC-RETAIL')\n",
    "\n",
    "# Filter retailer occuring in last 6 days\n",
    "data = data[~data.RtrCode.isin(rtr_last6days)]\n",
    "\n",
    "InvDate =  data['InvDate'].iloc[0]\n",
    "InvDate = str(InvDate)[0:10]\n",
    "\n",
    "maxdate= str(data['InvDate'].max())[0:10]\n",
    "print('\\nDate: ',maxdate)\n",
    "\n",
    "TotalRtrCount = data['RtrCode'].count()\n",
    "print('Unique retailers:', TotalRtrCount)\n",
    "\n",
    "## Retailer master\n",
    "rtr_master = data[['RtrCode','RtrName','DistName','RtrGroupCde1','RtrGroupCde','InvDate','PolypouchCount']].drop_duplicates()\n",
    "rtr_master['PolypouchCount'] = rtr_master['PolypouchCount'].astype(int)\n",
    "\n",
    "AM_RTR_in = data.groupby(['AMName','RtrGroupCde1'])['RtrCode'].count().reset_index()\n",
    "\n",
    "# Create text widget for output\n",
    "output_slider_variable = widgets.Text()\n",
    "\n",
    "# Define function to bind value of the input to the output variable \n",
    "def f(Lots):\n",
    "    output_slider_variable.value = str(Lots)\n",
    "\n",
    "print('\\nChoose number of Lots')\n",
    "# Create input slider with default value = 10  \n",
    "interact(f, Lots=(10, 100, 1))\n",
    "\n",
    "def picks(output_slider_variable,data):\n",
    "    # Create and output new int variable with value of slider\n",
    "    new_variable = int(output_slider_variable.value)\n",
    "\n",
    "    ## Choose number of retailers to choose\n",
    "    ## Weightage for AM\n",
    "    # Percentage of Retailers across AM-Wise        \n",
    "    TotalRtrCount = data['RtrCode'].count()\n",
    "    AM_RTR_WGT = data.groupby(['AMName','RtrGroupCde1'])['RtrCode'].count().reset_index()\n",
    "    AM_RTR_WGT['LotsPerAM'] = np.ceil((AM_RTR_WGT['RtrCode']/TotalRtrCount) * new_variable)\n",
    "\n",
    "\n",
    "    ## Split dataframe on AM's\n",
    "    # Select required rows\n",
    "    data1 = data[['ZM','AMName','RtrGroupCde1','RtrCode','RtrName','TotalQty','PolypouchCount']]\n",
    "    data2 = [rows for _, rows in data1.groupby(['AMName','RtrGroupCde1'])]\n",
    "    return data2,AM_RTR_WGT,new_variable\n",
    "    \n",
    "## Function to generate random Rtr's with AM weightage\n",
    "def randomRtrAmWise(i):\n",
    "    data3,AM_RTR_WGT,lots = picks(output_slider_variable,data)\n",
    "    # Retailer name\n",
    "    a = data3[i]['RtrCode'].tolist()\n",
    "\n",
    "    # Polypouch count as weight\n",
    "    ppc = data3[i]['PolypouchCount'].tolist() \n",
    "\n",
    "    c=int(AM_RTR_WGT['LotsPerAM'][i])\n",
    "    #random.shuffle(a)\n",
    "    l = random.choices(a, weights=ppc, k=c)\n",
    "    l.sort()\n",
    "    df_R = pd.DataFrame(l,columns = ['RtrCode'])\n",
    "    df_R['AMName'] = AM_RTR_WGT['AMName'][i]\n",
    "    return df_R,AM_RTR_WGT,lots\n",
    "    \n",
    "def randompick(rtr_master,AM_RTR_in):\n",
    "    df_RtrRP = pd.DataFrame()\n",
    "    for j in range(len( AM_RTR_in.index.tolist())):\n",
    "        df,AM_RTR_WGT,lots = randomRtrAmWise(j)\n",
    "        df_RtrRP = df_RtrRP.append(df)\n",
    "\n",
    "    df_RtrRP = df_RtrRP.merge(rtr_master,on='RtrCode')\n",
    "    df_RtrRP = df_RtrRP.groupby('RtrCode').head(2).reset_index(drop=True) # Keep 1st two instances of duplicates\n",
    "\n",
    "    index = df_RtrRP.reset_index().index\n",
    "    number_of_rows = len(index)\n",
    "    return df_RtrRP,lots,number_of_rows,AM_RTR_WGT\n",
    "\n",
    "def randompickAM(rtr_master,AM_RTR_in):\n",
    "    result,lots,number_of_rows,AM_RTR_WGT = randompick(rtr_master,AM_RTR_in)\n",
    "    while (number_of_rows!=lots):\n",
    "        if (number_of_rows==lots):\n",
    "            display(result)\n",
    "            print('Ok')\n",
    "        else:\n",
    "            result,lots,number_of_rows,AM_RTR_WGT = randompickAM(rtr_master,AM_RTR_in)\n",
    "            break\n",
    "    return result,lots,number_of_rows,AM_RTR_WGT\n",
    "\n",
    "print('\\n')\n",
    "# Button pick\n",
    "button = Button(description='Pick')\n",
    "\n",
    "out = Output()\n",
    "\n",
    "\n",
    "def on_click(_):\n",
    "    with out:\n",
    "        clear_output(True)\n",
    "        dr,lots,number_of_rows,AM_RTR_WGT = randompickAM(rtr_master,AM_RTR_in)\n",
    "        \n",
    "        max_count = 100\n",
    "\n",
    "        f = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "        display(f) # display the bar\n",
    "\n",
    "        count = 0\n",
    "        while count <= max_count:\n",
    "            f.value += 1 # signal to increment the progress bar\n",
    "            time.sleep(.1)\n",
    "            count += 1\n",
    "                \n",
    "        print('Count of lots: ',lots)\n",
    "        print('Count of picked retailers: ',number_of_rows)\n",
    "        print('\\n Split of Retailers chosen acorss AMs')\n",
    "        display(AM_RTR_WGT)\n",
    "        \n",
    "        print('\\nThe selected retailers on date', InvDate)\n",
    "        display(dr)\n",
    "        \n",
    "        # Save results\n",
    "        root = 'Results_csv' \n",
    "        sheet = 'results_' + InvDate + '.csv' \n",
    "        file_name = os.path.join(root,sheet)\n",
    "        print(file_name)\n",
    "        dr.to_csv(file_name,index=False)\n",
    "\n",
    "button.on_click(on_click)\n",
    "\n",
    "VBox([button,out])"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
